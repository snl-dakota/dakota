#@ s*: Label=FastTest
#@ s*: Label=AcceptanceTest
#@ s*: DakotaConfig=HAVE_ACRO
#@ p*: Label=FastTest
#@ p*: DakotaConfig=HAVE_ACRO
#@ p0: MPIProcs=3 CheckOutput='dakota.out.1'
#@ s0: UserMan=textbook_hybrid_strat
#@ [taxonomy:start]
#@ s0: [analysis:Optimization]
#@ s0: [method:GeneticAlgorithm]
#@ s0: [goal:Global]
#@ s0: [goal:BoundConstraints]
#@ s0: [variable:Continuous]
#@ s0: [model:MultiModal]
#@ s0: [model:NoDerivatives]
#@ [taxonomy:end]

# DAKOTA INPUT FILE: dakota_hybrid.in
# Dakota Input File: textbook_hybrid_strat.in                           #s0

# Hybrid optimization on the unconstrained Textbook test problem using
# 3 optimization methods in sequence:
#    genetic algorithm (in Coliny)
#    coordinate pattern search (in Coliny)
#    nonlinear programming (in OPT++)
# This provides an initial global search using a derivative-free method,
# followed by a local search using a derivative-free method, with a final
# local search using a full Newton method.

environment
  top_method_pointer = 'HS'
  graphics

method
  id_method = 'HS'
  hybrid sequential
#    iterator_servers = 3                   #p0
    method_pointer_list = 'GA' 'PS' 'NLP'		#s0,#s3,#p0
#    method_pointer_list = 'GA' 'PS' 'PS2'	#s1,#s2

method
  id_method = 'GA'
  coliny_ea
    seed = 1234
    population_size = 5 
# final_solutions = 3              #s3,#p0
  final_solutions = 1               #s0,#s1,#s2
  output verbose
  model_pointer = 'M1'

method
  id_method = 'PS'
  coliny_pattern_search stochastic
#   max_function_evaluations = 100     #s1
    seed = 1234
    initial_delta = 0.1
    threshold_delta = 1.e-4
    solution_target = 1.e-10
    exploratory_moves basic_pattern
    output verbose
    model_pointer = 'M1'

#method,                              #s1,#s2
#  id_method = 'PS2'				          #s1,#s2
#  coliny_pattern_search stochastic		#s1,#s2
#    max_function_evaluations = 10		#s1,#s2
#    seed = 1234	      			        #s1,#s2
#    initial_delta = 0.1			        #s1,#s2
#    threshold_delta = 1.e-4			    #s1,#s2
#    solution_target = 1.e-10			    #s1,#s2
#    exploratory_moves basic_pattern	#s1,#s2
#    output verbose    				        #s1,#s2
#    model_pointer = 'M1'				      #s1,#s2

method	  	  				                #s0,#s3,#p0
  id_method = 'NLP'				            #s0,#s3,#p0
  optpp_newton  				              #s0,#s3,#p0
    gradient_tolerance = 1.e-12			  #s0,#s3,#p0
    convergence_tolerance = 1.e-15		#s0,#s3,#p0
    output verbose	  			          #s0,#s3,#p0
    model_pointer = 'M2'				      #s0,#s3,#p0

model
  id_model = 'M1'
  single
    interface_pointer = 'I1'		    #s0
  variables_pointer = 'V1'          #s0
  responses_pointer = 'R1'

model
  id_model = 'M2'
  single
    interface_pointer = 'I1'		    #s0
  variables_pointer = 'V1'          #s0
  responses_pointer = 'R2'

variables
  id_variables = 'V1'               #s0
  continuous_design = 2
    initial_point    0.6    0.7
    upper_bounds     5.8    2.9
    lower_bounds     0.5   -2.9
    descriptors      'x1'   'x2'

interface
  id_interface = 'I1'               #s0
  analysis_drivers =  'text_book'
    direct				                    #s0,#s1,#s3,#p0
#   system asynch   			            #s2

responses
  id_responses = 'R1'
  objective_functions = 1
  no_gradients
  no_hessians

responses
  id_responses = 'R2'
  objective_functions = 1
  analytic_gradients
  analytic_hessians
