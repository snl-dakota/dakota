Blurb::
Use second Kraskov algorithm to compute mutual information
Description::
This algorithm is derived in :cite:p:`Kra04` . The mutual information between
:math:`m`  random variables is approximated by


.. math:: 

   I_{2}(X_{1}, X_{2}, \ldots, X_{m}) = \psi(k) + (m-1)\psi(N) - (m-1)/k -
   < \psi(n_{x_{1}}) + \psi(n_{x_{2}}) + \ldots + \psi(n_{x_{m}}) >,

where :math:`\psi`  is the digamma function, :math:`k`  is the number of nearest
neighbors being used, and :math:`N`  is the
number of samples available for the joint distribution of the random variables.
For each point :math:`z_{i} = (x_{1,i}, x_{2,i}, \ldots, x_{m,i})`  in the joint
distribution, :math:`z_{i}`  and its :math:`k`  nearest neighbors are projected into
each marginal subpsace. For each subspace :math:`j = 1, \ldots, m` ,
:math:`\epsilon_{j,i}`  is defined as the radius of the :math:`l_{\infty}` -ball
containing all :math:`k+1`  points. Then, :math:`n_{x_{j,i}}`  is the number of points
in the :math:`j` -th subspace within a distance of :math:`\epsilon_{j,i}`  from the
point :math:`x_{j,i}` . The angular brackets denote that the average of
:math:`\psi(n_{x_{j,i}})`  is taken over all points :math:`i = 1, \ldots, N` .
Topics::

Examples::

.. code-block::

    method
     bayes_calibration queso
       dram
       seed = 34785
       chain_samples = 1000
       posterior_stats mutual_info
      ksg2



.. code-block::

    method
     bayes_calibration
       queso
       dram
       chain_samples = 1000 seed = 348
      experimental_design
       initial_samples = 5
       num_candidates = 10
       max_hifi_evaluations = 3
       ksg2


Theory::

Faq::

See_Also::
