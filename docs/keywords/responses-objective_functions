Blurb::
Response type suitable for optimization
Description::
Specifies the number (1 or more) of objective functions :math:`f_j`
returned to Dakota for use in the general optimization problem
formulation:

.. math::

   \begin{eqnarray*}
   \hbox{minimize:} & & f(\mathbf{x}) = \sum_j{w_j f_j} \\
   & & \mathbf{x} \in \Re^{n} \\
   \hbox{subject to:} & &
   \mathbf{g}_{L} \leq \mathbf{g(x)} \leq \mathbf{g}_U \\
   & & \mathbf{h(x)}=\mathbf{h}_{t} \\
   & & \mathbf{a}_{L} \leq \mathbf{A}_i\mathbf{x} \leq \mathbf{a}_U \\
   & & \mathbf{A}_{e}\mathbf{x}=\mathbf{a}_{t} \\
   & & \mathbf{x}_{L} \leq \mathbf{x} \leq \mathbf{x}_U
   \end{eqnarray*}

Unless :dakkw:`responses-objective_functions-sense` is specified, Dakota
will minimize the objective functions.

The keywords
:dakkw:`responses-objective_functions-nonlinear_inequality_constraints` and
:dakkw:`responses-objective_functions-nonlinear_equality_constraints`
specify the number of nonlinear inequality constraints *g*, and nonlinear
equality constraints *h*, respectively.  When interfacing to external
applications, the responses must be returned to Dakota in this order
in the :dakkw:`interface-analysis_drivers-fork-results_file` :


1. objective functions
2. nonlinear_inequality_constraints
3. nonlinear_equality_constraints


An optimization problem's linear constraints are provided to the
solver at startup only and do not need to be included in the data
returned on every function evaluation. Linear constraints are
therefore specified in the :dakkw:`variables` block through the
:dakkw:`variables-linear_inequality_constraint_matrix` :math:`A_i`  and
:dakkw:`variables-linear_equality_constraint_matrix` :math:`A_e` .

Lower and upper bounds on the design variables *x* are also
specified in the :dakkw:`variables` block.

The optional keywords relate to scaling the objective functions (for
better numerical results), formulating the problem as minimization or
maximization, and dealing with multiple objective functions through
:dakkw:`responses-objective_functions-weights` *w*. If scaling is used,
it is applied before multi-objective weighted sums are formed, so,
e.g, when both weighting and characteristic value scaling are present
the ultimate objective function would be:


.. math::  f = \sum_{j=1}^{n} w_{j} \frac{ f_{j} }{ s_j }

Topics::

Examples::

Theory::

Faq::

See_Also::
