Blurb::
Local multi-point model via two-point nonlinear approximation
Description::
*TANA* stands for Two Point Adaptive Nonlinearity Approximation.

The TANA-3 method :cite:p:`Xu98` is a multipoint approximation method
based on the two point exponential approximation :cite:p:`Fad90`. This
approach involves a Taylor series approximation in intermediate
variables where the powers used for the intermediate variables are
selected to match information at the current and previous expansion
points.

*Known Issue: When using discrete variables, there have been
sometimes significant differences in surrogate behavior observed
across computing platforms in some cases.  The cause has not yet been
fully diagnosed and is currently under investigation.  In addition,
guidance on appropriate construction and use of surrogates with
discrete variables is under development.  In the meantime, users
should therefore be aware that there is a risk of inaccurate results
when using surrogates with discrete variables.*
Topics::

Examples::

Theory::
The form of the TANA model is:


.. math::  \hat{f}({\bf x}) \approx f({\bf x}_2) + \sum_{i=1}^n
 \frac{\partial f}{\partial x_i}({\bf x}_2) \frac{x_{i,2}^{1-p_i}}{p_i}
 (x_i^{p_i} - x_{i,2}^{p_i}) + \frac{1}{2} \epsilon({\bf x}) \sum_{i=1}^n
 (x_i^{p_i} - x_{i,2}^{p_i})^2 

where :math:`n`  is the number of variables and:


.. math::  p_i = 1 + \ln \left[ \frac{\frac{\partial f}{\partial x_i}({\bf x}_1)}
 {\frac{\partial f}{\partial x_i}({\bf x}_2)} \right] \left/
 \ln \left[ \frac{x_{i,1}}{x_{i,2}} \right] \right.
 \epsilon({\bf x}) = \frac{H}{\sum_{i=1}^n (x_i^{p_i} - x_{i,1}^{p_i})^2 +
 \sum_{i=1}^n (x_i^{p_i} - x_{i,2}^{p_i})^2}
 H = 2 \left[ f({\bf x}_1) - f({\bf x}_2) - \sum_{i=1}^n
 \frac{\partial f}{\partial x_i}({\bf x}_2) \frac{x_{i,2}^{1-p_i}}{p_i}
 (x_{i,1}^{p_i} - x_{i,2}^{p_i}) \right] 

and :math:`{\bf x}_2`  and :math:`{\bf x}_1`  are the current and previous expansion
points. Prior to the availability of two expansion points, a
first-order Taylor series is used.
Faq::

See_Also::
