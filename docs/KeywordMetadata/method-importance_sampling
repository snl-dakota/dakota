Blurb::
Importance sampling
Description::
The \c importance_sampling method is based on ideas in reliability modeling.

An initial Latin Hypercube sampling is performed to generate an initial set of samples.
These initial samples are augmented with samples from an importance density as follows: 
\li The variables are transformed to standard normal space. 
\li In the transformed space, 
    the importance density is a set of normal densities centered around points which 
    are in the failure region. 
\li Note that this is similar in spirit to the reliability 
    methods, in which importance sampling is centered around a Most Probable Point (MPP). 
\li In the case of the LHS samples, the importance sampling density will simply by 
    a mixture of normal distributions centered around points in the failure region. 

<b> Options </b>

Choose one of the importance sampling options:
\li \c import 
\li \c adapt_import 
\li \c mm_adapt_import 

The options for importance sampling are as follows: \c import centers a sampling 
density at one of the initial LHS samples identified in the failure region. 
It then generates the importance samples, weights them by their probability of occurence 
given the original density, and calculates the required probability (CDF or CCDF level). 
\c adapt_import is the same as \c import but is performed iteratively until the 
failure probability estimate converges. 
\c mm_adapt_import starts with all of the samples located in the failure region 
to build a multimodal sampling density. First, it uses a small number of samples around 
each of the initial samples in the failure region. Note that these samples 
are allocated to the different points based on their relative probabilities of occurrence:
more probable points get more samples. This early part of the approach is done 
to search for "representative" points. Once these are located, the multimodal sampling 
density is set and then \c mm_adapt_import proceeds similarly to \c adapt_import (sample 
until convergence). 

Topics::	uncertainty_quantification, aleatory_uncertainty_quantification_methods, sampling
Examples::
Theory::
Importance sampling is a method that allows one to estimate statistical 
quantities such as failure probabilities (e.g. the probability that 
a response quantity will exceed a threshold or fall below a threshold value)
in a way that is more efficient than Monte Carlo sampling. The core idea 
in importance sampling is that one generates samples that preferentially 
samples important regions in the space (e.g. in or near the failure region 
or user-defined region of interest), and then appropriately weights 
the samples to obtain an unbiased estimate of the failure probability
\cite Srinivasan2002. 
In importance sampling, the samples are generated from a density which is 
called the importance density: it is not the original probability density 
of the input distributions. The importance density should be centered near the 
failure region of interest. For black-box simulations such as those commonly 
interfaced with %Dakota, it is difficult to specify the importance density a priori: 
the user often does not know where the failure region lies, especially in a high-dimensional 
space. \cite Swiler2010. 
We have developed two importance sampling approaches which do not 
rely on the user explicitly specifying an importance density. 

Faq::
See_Also::	method-adaptive_sampling, method-gpais, method-local_reliability, method-global_reliability, method-sampling, method-polynomial_chaos, method-stoch_collocation
